# Docker Compose configuration for OvaInsightXAI Backend
# Use this for local development and testing before cloud deployment

version: '3.8'

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BUILD_VERSION: v3
    container_name: ovainsight-backend
    ports:
      - "${PORT:-8000}:8000"
    environment:
      # Application settings
      - PORT=8000
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-http://localhost:3000,http://localhost:3001}
      
      # Model configuration (use defaults from Dockerfile)
      # - MODEL_PATH=/app/app/model/model.pkl
      # - ALLOW_MODEL_DOWNLOAD=0
      
      # Performance tuning
      - PYTHONUNBUFFERED=1
      - OMP_NUM_THREADS=2
      - MKL_NUM_THREADS=2
      - OPENBLAS_NUM_THREADS=2
      - TORCH_NUM_THREADS=2
      
      # Optional: Brain tumor model architecture (if needed)
      # - BRAIN_TUMOR_MODEL_ARCH=pvt_v2_b1
    
    # Health check configuration
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 60s
    
    # Resource limits for cloud deployment
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    
    # Restart policy
    restart: unless-stopped

# Networks (optional, for multi-service deployments)
networks:
  default:
    name: ovainsight-network
