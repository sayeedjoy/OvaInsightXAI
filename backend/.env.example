# OvaInsightXAI Backend Environment Configuration
# Copy this file to .env and configure for your deployment

# ============================================================================
# Server Configuration
# ============================================================================

# Port to run the server on (default: 8000)
PORT=8000

# Allowed origins for CORS (comma-separated)
# For production, replace with your actual frontend URL
ALLOWED_ORIGINS=http://localhost:3000,https://your-frontend-domain.com

# ============================================================================
# Model Configuration
# ============================================================================

# Path to the ovarian cancer model file (optional, uses default if not set)
# MODEL_PATH=/app/app/model/model.pkl

# Allow downloading model from CDN if not found (set to 1 to enable)
# ALLOW_MODEL_DOWNLOAD=0

# Brain tumor model architecture (if state_dict requires manual specification)
# Common options: pvt_v2_b1, resnet50, efficientnet_b0, vit_base_patch16_224
# BRAIN_TUMOR_MODEL_ARCH=pvt_v2_b1

# ============================================================================
# Performance Tuning
# ============================================================================

# Number of threads for numerical computations (reduce for memory-constrained environments)
OMP_NUM_THREADS=2
MKL_NUM_THREADS=2
OPENBLAS_NUM_THREADS=2
TORCH_NUM_THREADS=2

# Python settings
PYTHONUNBUFFERED=1
PYTHONDONTWRITEBYTECODE=1

# ============================================================================
# Logging
# ============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ============================================================================
# XAI Performance Tuning (Explainable AI)
# ============================================================================
# These settings control the speed/quality tradeoff for XAI explanations.
# Lower values = faster but less detailed. Higher values = more thorough but slower.

# SHAP (Occlusion-based sensitivity)
SHAP_IMAGE_PATCH_SIZE=32        # Size of occlusion patch (default: 32, faster with larger values)
SHAP_IMAGE_STRIDE=16            # Stride for moving patch (default: 16, faster with larger values)
SHAP_IMAGE_BATCH_SIZE=32        # Batch size for inference (default: 32)

# LIME (Local Interpretable Model-agnostic Explanations)
LIME_IMAGE_NUM_SAMPLES=100      # Number of perturbation samples (default: 100, was 300)
LIME_IMAGE_BATCH_SIZE=16        # Batch size for inference (default: 16)
LIME_IMAGE_NUM_FEATURES=10      # Number of top features to return

# PDP (Partial Dependence Plots)
PDP_IMAGE_GRID_SIZE=3           # Grid size for patches (default: 3, i.e., 3x3=9 patches)
PDP_IMAGE_N_GRID_POINTS=5       # Number of intensity levels (default: 5)
PDP_IMAGE_BATCH_SIZE=16         # Batch size for inference

# ICE (Individual Conditional Expectation)
ICE_IMAGE_GRID_SIZE=3           # Grid size for patches (default: 3)
ICE_IMAGE_N_GRID_POINTS=5       # Number of intensity levels (default: 5)
ICE_IMAGE_N_SAMPLES=3           # Number of sample curves per patch (default: 3)
ICE_IMAGE_BATCH_SIZE=16         # Batch size for inference

# ALE (Accumulated Local Effects)
ALE_IMAGE_GRID_SIZE=3           # Grid size for patches (default: 3)
ALE_IMAGE_N_BINS=4              # Number of bins for ALE computation (default: 4)
ALE_IMAGE_BATCH_SIZE=16         # Batch size for inference

# XAI general settings
XAI_TIMEOUT_SECONDS=60          # Timeout for each XAI computation
XAI_PARALLEL=true               # Run XAI methods in parallel (recommended: true)
